{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import (\n",
    "    generate_translation_several_datasets,\n",
    "    load_model_benchmark,\n",
    "    translate_batched_OPT,\n",
    "    translate_batched_Llama3,\n",
    "    eval_metrics,\n",
    "    make_parallel_plot,\n",
    "    make_bar_plot,\n",
    "    make_bar_plot_all_metrics\n",
    ")\n",
    "\n",
    "from utils.eval_params import num_beams, temperature, max_new_tokens, top_p\n",
    "#num_beams = 5\n",
    "#max_new_tokens = 512\n",
    "#top_p = 0.9\n",
    "#temperature = 0.6\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Causal LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_tgt_icl_fn_CausalModel(number_examples):\n",
    "    \"\"\"Works for ALMA, OPT-instruct, BLOOMz, and any GPT model non instruct\"\"\"\n",
    "    def get_input_targets_icl_CausalModel(dataset, source_lang, target_lang):\n",
    "        language_name = {\"en\": \"English\", \"de\": \"German\", \"ru\": \"Russian\", \"is\": \"Islandic\", \"zh\": \"Chinese\", \"cs\": \"Czech\"}\n",
    "        source_lang_name = language_name[source_lang]\n",
    "        target_lang_name = language_name[target_lang]\n",
    "        # Use base formulation \"Translate this from Chinese to English:\\nChinese: 我爱机器翻译。\\nEnglish:\"\n",
    "        sources = [example[source_lang] for example in dataset[f\"{source_lang}-{target_lang}\"]]\n",
    "\n",
    "        inputs = []\n",
    "        offset_seed = 0\n",
    "        print(\"Generating prompts for In-Context learning...\")\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            np.random.seed(i + offset_seed)\n",
    "            idx = np.arange(len(dataset))\n",
    "            idx = np.random.choice(idx, number_examples)\n",
    "            while i in idx: # Make sure the translation to do is not in the examples\n",
    "                offset_seed += 1\n",
    "                np.random.seed(i + offset_seed)\n",
    "                idx = np.arange(len(dataset))\n",
    "                idx = np.random.choice(idx, number_examples)\n",
    "            examples = [dataset[f\"{source_lang}-{target_lang}\"][n] for n in idx]\n",
    "            inp = f\"Here are examples of translations from {source_lang_name} to {target_lang_name}:\"\n",
    "            for n in range(number_examples):\n",
    "                example_source, example_target = examples[n][source_lang], examples[n][target_lang]\n",
    "                inp += f\"[START]\\n{source_lang_name}: {example_source} \\n{target_lang_name}: {example_target}\\n[END]\"\n",
    "            inp += f\"\\n Using the examples, translate from {source_lang_name} to {target_lang_name}:\"\n",
    "            input_source = dataset[f\"{source_lang}-{target_lang}\"][i][source_lang]\n",
    "            inp += f\"[START]\\n{source_lang_name}: {input_source} \\n{target_lang_name}:\"\n",
    "            inputs.append(inp)\n",
    "\n",
    "        targets = [example[target_lang] for example in dataset[f\"{source_lang}-{target_lang}\"]]\n",
    "        return sources, inputs, targets\n",
    "    return get_input_targets_icl_CausalModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Careful, the code runs for ALMA, but 16GB is not enough to use 7B models quantized in 8 bits with one example...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "dataset_names = [\"wnt23\"]\n",
    "\n",
    "model_names = [\"opt-instruct\"]\n",
    "model_sizes = [None]\n",
    "\n",
    "batch_size = 1\n",
    "reduce_size = 4\n",
    "\n",
    "number_examples = 1\n",
    "\n",
    "generate_translation_several_datasets(directions, dataset_names, model_names, model_sizes, batch_size, reduce_size,\n",
    "                                    load_model_and_tokenizer_fn = load_model_benchmark,\n",
    "                                    get_input_targets_fn = get_input_tgt_icl_fn_CausalModel(number_examples),\n",
    "                                    tslt_fn = translate_batched_OPT,\n",
    "                                    translation_folder = f\"evaluationsICL_{number_examples}examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Instruct Causal LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_tgt_icl_fn_Instruct(number_examples):\n",
    "    def get_input_targets_icl_Instruct(dataset, source_lang, target_lang):\n",
    "        \"\"\"\n",
    "        Work at least for Qwen2.5 and Llama3\n",
    "        \"\"\"\n",
    "        if not os.path.exists(\"./cache_perso\"):\n",
    "            os.makedirs(\"./cache_perso\")\n",
    "        if os.path.exists(f\"./cache_perso/ICL_{source_lang}-{target_lang}_{number_examples}\"):\n",
    "            print(\"Using cached data...\")\n",
    "            with open(f\"./cache_perso/ICL_{source_lang}-{target_lang}_{number_examples}\", \"rb\") as f:\n",
    "                cached = pickle.load(f)\n",
    "            sources = cached[\"sources\"]\n",
    "            inputs = cached[\"inputs\"]\n",
    "            targets = cached[\"targets\"]\n",
    "            return sources, inputs, targets\n",
    "        language_name = {\"en\": \"English\", \"de\": \"German\", \"ru\": \"Russian\", \"is\": \"Islandic\", \"zh\": \"Chinese\", \"cs\": \"Czech\"}\n",
    "        source_lang_name = language_name[source_lang]\n",
    "        target_lang_name = language_name[target_lang]\n",
    "        sources = [example[source_lang] for example in dataset[f\"{source_lang}-{target_lang}\"]]\n",
    "        inputs = []\n",
    "        offset_seed = 0\n",
    "        print(\"Generating prompts for In-Context learning...\")\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            np.random.seed(i + offset_seed)\n",
    "            idx = np.arange(len(dataset))\n",
    "            idx = np.random.choice(idx, number_examples)\n",
    "            while i in idx: # Make sure the translation to do is not in the examples\n",
    "                offset_seed += 1\n",
    "                np.random.seed(i + offset_seed)\n",
    "                idx = np.arange(len(dataset))\n",
    "                idx = np.random.choice(idx, number_examples)\n",
    "            examples = [dataset[f\"{source_lang}-{target_lang}\"][n] for n in idx]\n",
    "            inp = f\"Here are examples of translations from {source_lang_name} to {target_lang_name}:\"\n",
    "            for n in range(number_examples):\n",
    "                example_source, example_target = examples[n][source_lang], examples[n][target_lang]\n",
    "                inp += f\"\\n[EXAMPLE {n+1}]\\n{source_lang_name}: {example_source} \\n{target_lang_name}: {example_target}\"\n",
    "            inp += f\"\\n Using the examples, translate from {source_lang_name} to {target_lang_name}:\"\n",
    "            input_source = dataset[f\"{source_lang}-{target_lang}\"][i][source_lang]\n",
    "            inp += f\"[TASK]\\n{source_lang_name}: {input_source} \\n{target_lang_name}:\"\n",
    "            inputs.append([\n",
    "                {\"role\": \"system\", \"content\": \"You are a translator, you output only the translation in the desired language.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{inp}\"}])\n",
    "\n",
    "        targets = [example[target_lang] for example in dataset[f\"{source_lang}-{target_lang}\"]]\n",
    "        with open(f\"./cache_perso/ICL_{source_lang}-{target_lang}_{number_examples}\", \"wb\") as f:\n",
    "            pickle.dump({\"sources\": sources, \"inputs\": inputs, \"targets\": targets}, f, pickle.HIGHEST_PROTOCOL)\n",
    "        return sources, inputs, targets\n",
    "    return get_input_targets_icl_Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "dataset_names = [\"wnt23\"]\n",
    "\n",
    "model_names = [\"llama3\"]\n",
    "model_sizes = [\"3B\"]\n",
    "\n",
    "batch_size = 1\n",
    "reduce_size = 50\n",
    "\n",
    "for number_examples in [1, 2, 3, 4]: #More than 4 is OOM\n",
    "    generate_translation_several_datasets(directions, dataset_names, model_names, model_sizes, batch_size, reduce_size,\n",
    "                                        load_model_and_tokenizer_fn = load_model_benchmark,\n",
    "                                        get_input_targets_fn = get_input_tgt_icl_fn_Instruct(number_examples),\n",
    "                                        tslt_fn = translate_batched_Llama3,\n",
    "                                        translation_folder = f\"evaluationsICL_{number_examples}examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "dataset_names = [\"flores\"]\n",
    "\n",
    "model_names = [\"llama3\"]\n",
    "model_sizes = [\"3B\"]\n",
    "\n",
    "batch_size = 4\n",
    "reduce_size = 100\n",
    "\n",
    "for number_examples in [1, 2, 3, 4, 5]:\n",
    "    generate_translation_several_datasets(directions, dataset_names, model_names, model_sizes, batch_size, reduce_size,\n",
    "                                        load_model_and_tokenizer_fn = load_model_benchmark,\n",
    "                                        get_input_targets_fn = get_input_tgt_icl_fn_Instruct(number_examples),\n",
    "                                        tslt_fn = translate_batched_Llama3,\n",
    "                                        translation_folder = f\"evaluationsICL_{number_examples}examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number_examples in [1, 2, 3, 4]:\n",
    "    with open(f\"./generated_translations/evaluationsICL_{number_examples}examples/wnt23_llama3-3B_en-de_red-50.pkl\", \"rb\") as f:\n",
    "        translations = pickle.load(f)\n",
    "    print(\"First translation:\", translations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number_examples in [1, 2, 3, 4, 5]:\n",
    "    with open(f\"./generated_translations/evaluationsICL_{number_examples}examples/flores_llama3-3B_en-de_red-100.pkl\", \"rb\") as f:\n",
    "        translations = pickle.load(f)\n",
    "    print(\"First translation:\", translations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "metric_names = [\"rouge\", \"bleu\", \"sacrebleu\", \"chrf\", \"comet\", \"meteor\", \"bertscore\"]\n",
    "\n",
    "dataset_names = [\"wnt23\"] # Careful to use one dataset at a time otherwise get_input_tgt_rag_fn_Instruct will not be consistent\n",
    "reduce_sizes = [50]\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\"]\n",
    "model_sizes = [\"3B\"]\n",
    "\n",
    "for number_examples in [1, 2, 3, 4]:\n",
    "    eval_metrics(metric_names, directions, dataset_names, model_names, model_sizes, reduce_sizes,\n",
    "                get_input_targets_fn=get_input_tgt_icl_fn_Instruct(number_examples),\n",
    "                translation_folder=f\"evaluationsICL_{number_examples}examples\",\n",
    "                additionnal_name=f\"ICL_{number_examples}examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute BLEURT metric alone because it is not offloaded of the GPU, need to restart the kernel...\n",
    "metric_names = [\"bleurt\"]\n",
    "\n",
    "dataset_names = [\"wnt23\"] # Careful to use one dataset at a time otherwise get_input_tgt_rag_fn_Instruct will not be consistent \n",
    "reduce_sizes = [50]\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\"]\n",
    "model_sizes = [\"3B\"]\n",
    "\n",
    "for number_examples in [1, 2, 3, 4]:\n",
    "    eval_metrics(metric_names, directions, dataset_names, model_names, model_sizes, reduce_sizes,\n",
    "                get_input_targets_fn=get_input_tgt_icl_fn_Instruct(number_examples),\n",
    "                translation_folder=f\"evaluationsICL_{number_examples}examples\",\n",
    "                additionnal_name=f\"ICL_{number_examples}examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "metric_names = [\"rouge\", \"bleu\", \"sacrebleu\", \"chrf\", \"comet\", \"meteor\", \"bertscore\"]\n",
    "\n",
    "dataset_names = [\"flores\"] # Careful to use one dataset at a time otherwise get_input_tgt_rag_fn_Instruct will not be consistent\n",
    "reduce_sizes = [100]\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\"]\n",
    "model_sizes = [\"3B\"]\n",
    "\n",
    "for number_examples in [1, 2, 3, 4, 5]:\n",
    "    eval_metrics(metric_names, directions, dataset_names, model_names, model_sizes, reduce_sizes,\n",
    "                get_input_targets_fn=get_input_tgt_icl_fn_Instruct(number_examples),\n",
    "                translation_folder=f\"evaluationsICL_{number_examples}examples\",\n",
    "                additionnal_name=f\"ICL_{number_examples}examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comput BLEURT metric alone because it is not offloaded of the GPU, need to restart the kernel...\n",
    "metric_names = [\"bleurt\"]\n",
    "\n",
    "dataset_names = [\"flores\"] # Careful to use one dataset at a time otherwise get_input_tgt_rag_fn_Instruct will not be consistent \n",
    "reduce_sizes = [100]\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\"]\n",
    "model_sizes = [\"3B\"]\n",
    "\n",
    "for number_examples in [1, 2, 3, 4, 5]:\n",
    "    eval_metrics(metric_names, directions, dataset_names, model_names, model_sizes, reduce_sizes,\n",
    "                get_input_targets_fn=get_input_tgt_icl_fn_Instruct(number_examples),\n",
    "                translation_folder=f\"evaluationsICL_{number_examples}examples\",\n",
    "                additionnal_name=f\"ICL_{number_examples}examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WNT23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"ROUGE-Lsum\",\n",
    "                \"BLEU\", \"SacreBLEU\", \"chrF\", \"chrF++\",\n",
    "                \"COMET\", \"BLEURT\", \"BERTscore\", \"METEOR\"]\n",
    "\n",
    "dataset_names = [\"wnt23\"]\n",
    "reduce_sizes = [50]\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\"]\n",
    "model_sizes = [\"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\"]\n",
    "additionnal_names = [None,\n",
    "                     \"ICL_1examples\",\n",
    "                     \"ICL_2examples\",\n",
    "                     \"ICL_3examples\",\n",
    "                     \"ICL_4examples\"]\n",
    "\n",
    "\n",
    "make_parallel_plot(directions,\n",
    "                    model_names, model_sizes,\n",
    "                    dataset_names, reduce_sizes,\n",
    "                    metric_names,\n",
    "                    list_colors_per = [\"model\"],\n",
    "                    additionnal_names=additionnal_names,\n",
    "                    savepath = \"./results/evaluations_figures/ICL_RAG_parallelplot/ICL_eval_parrallel_model_wnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"ROUGE-Lsum\",\n",
    "                \"BLEU\", \"SacreBLEU\", \"chrF\", \"chrF++\",\n",
    "                \"COMET\", \"BLEURT\", \"BERTscore\", \"METEOR\"]\n",
    "\n",
    "dataset_name = \"wnt23\"\n",
    "reduce_size = 50\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\"]\n",
    "model_sizes = [\"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\"]\n",
    "additionnal_names = [None,\n",
    "                     \"ICL_1examples\",\n",
    "                     \"ICL_2examples\",\n",
    "                     \"ICL_3examples\",\n",
    "                     \"ICL_4examples\"]\n",
    "\n",
    "make_bar_plot(directions,\n",
    "                model_names, model_sizes,\n",
    "                dataset_name, reduce_size,\n",
    "                metric_names,\n",
    "                additionnal_names=additionnal_names,\n",
    "                width=0.15,\n",
    "                cmap=\"rainbow\",\n",
    "                savepath = \"./results/evaluations_figures/ICL_barplot/barplot_all_models_ICL_wnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bar plot per direction\n",
    "metric_names = [\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"ROUGE-Lsum\",\n",
    "                \"BLEU\", \"SacreBLEU\", \"chrF\", \"chrF++\",\n",
    "                \"COMET\", \"BLEURT\", \"BERTscore\", \"METEOR\"]\n",
    "\n",
    "dataset_name = \"wnt23\"\n",
    "reduce_size = 50\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\"]\n",
    "model_sizes = [\"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\"]\n",
    "additionnal_names = [None,\n",
    "                     \"ICL_1examples\",\n",
    "                     \"ICL_2examples\",\n",
    "                     \"ICL_3examples\",\n",
    "                     \"ICL_4examples\"]\n",
    "\n",
    "make_bar_plot_all_metrics(directions, model_names, model_sizes, dataset_name, reduce_size, metric_names, additionnal_names,\n",
    "                          cmap = \"rainbow\",\n",
    "                        savepath = \"./results/evaluations_figures/ICL_barplot/barplot_all_metrics_ICL_wnt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"ROUGE-Lsum\",\n",
    "                \"BLEU\", \"SacreBLEU\", \"chrF\", \"chrF++\",\n",
    "                \"COMET\", \"BLEURT\", \"BERTscore\", \"METEOR\"]\n",
    "\n",
    "dataset_names = [\"flores\"]\n",
    "reduce_sizes = [100]\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\"]\n",
    "model_sizes = [\"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\"]\n",
    "additionnal_names = [None,\n",
    "                     \"ICL_1examples\",\n",
    "                     \"ICL_2examples\",\n",
    "                     \"ICL_3examples\",\n",
    "                     \"ICL_4examples\",\n",
    "                     \"ICL_5examples\"]\n",
    "\n",
    "\n",
    "make_parallel_plot(directions,\n",
    "                    model_names, model_sizes,\n",
    "                    dataset_names, reduce_sizes,\n",
    "                    metric_names,\n",
    "                    list_colors_per = [\"model\"],\n",
    "                    additionnal_names=additionnal_names,\n",
    "                    savepath = \"./results/evaluations_figures/ICL_RAG_parallelplot/ICL_eval_parrallel_model_flores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"ROUGE-Lsum\",\n",
    "                \"BLEU\", \"SacreBLEU\", \"chrF\", \"chrF++\",\n",
    "                \"COMET\", \"BLEURT\", \"BERTscore\", \"METEOR\"]\n",
    "\n",
    "dataset_name = \"flores\"\n",
    "reduce_size = 100\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\"]\n",
    "model_sizes = [\"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\"]\n",
    "additionnal_names = [None,\n",
    "                     \"ICL_1examples\",\n",
    "                     \"ICL_2examples\",\n",
    "                     \"ICL_3examples\",\n",
    "                     \"ICL_4examples\"]\n",
    "\n",
    "make_bar_plot(directions,\n",
    "                model_names, model_sizes,\n",
    "                dataset_name, reduce_size,\n",
    "                metric_names,\n",
    "                additionnal_names=additionnal_names,\n",
    "                width=0.15,\n",
    "                cmap=\"rainbow\",\n",
    "                savepath = \"./results/evaluations_figures/ICL_barplot/barplot_all_models_ICL_flores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bar plot per direction\n",
    "metric_names = [\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\", \"ROUGE-Lsum\",\n",
    "                \"BLEU\", \"SacreBLEU\", \"chrF\", \"chrF++\",\n",
    "                \"COMET\", \"BLEURT\", \"BERTscore\", \"METEOR\"]\n",
    "\n",
    "dataset_name = \"flores\"\n",
    "reduce_size = 100\n",
    "\n",
    "directions = [\"en-de\", \"de-en\",\n",
    "              \"en-cs\", \"cs-en\",\n",
    "              \"en-is\", \"is-en\",\n",
    "              \"en-zh\", \"zh-en\",\n",
    "              \"en-ru\", \"ru-en\"]\n",
    "\n",
    "model_names = [\"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\",\n",
    "               \"llama3\"]\n",
    "model_sizes = [\"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\",\n",
    "               \"3B\"]\n",
    "additionnal_names = [None,\n",
    "                     \"ICL_1examples\",\n",
    "                     \"ICL_2examples\",\n",
    "                     \"ICL_3examples\",\n",
    "                     \"ICL_4examples\"]\n",
    "\n",
    "make_bar_plot_all_metrics(directions, model_names, model_sizes, dataset_name, reduce_size, metric_names, additionnal_names,\n",
    "                        savepath = \"./results/evaluations_figures/ICL_barplot/barplot_all_metrics_ICL_flores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNLP-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Dataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import huggingface_hub\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wnt = load_dataset(\"haoranxu/WMT23-Test\", \"en-cs\")[\"test\"]\n",
    "print(len(ds_wnt), ds_wnt[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataset(inputs: list[str], sources: list[str], targets, final_nb: list[str]) -> tuple[list[str], list[str], list[str]]:\n",
    "    \"\"\"\n",
    "    Selects randomly the samples of the evaluation corpus\n",
    "    \"\"\"\n",
    "    idx = np.arange(len(inputs))\n",
    "    np.random.seed(42)\n",
    "    idx = np.random.choice(idx, final_nb)\n",
    "    return [inputs[i] for i in idx], [sources[i] for i in idx], [targets[i] for i in idx]\n",
    "\n",
    "def get_input_tgt_icl_fn(number_examples):\n",
    "    def get_input_targets_icl_ALMA(dataset, source_lang, target_lang):\n",
    "        language_name = {\"en\": \"English\", \"de\": \"German\", \"ru\": \"Russian\", \"is\": \"Islandic\", \"zh\": \"Chinese\", \"cs\": \"Czech\"}\n",
    "        source_lang_name = language_name[source_lang]\n",
    "        target_lang_name = language_name[target_lang]\n",
    "        # Use base formulation \"Translate this from Chinese to English:\\nChinese: 我爱机器翻译。\\nEnglish:\"\n",
    "        sources = [example[source_lang] for example in dataset[f\"{source_lang}-{target_lang}\"]]\n",
    "\n",
    "        inputs = []\n",
    "        offset_seed = 0\n",
    "        for i in range(len(dataset)):\n",
    "            np.random.seed(i + offset_seed)\n",
    "            idx = np.arange(len(dataset))\n",
    "            idx = np.random.choice(idx, number_examples)\n",
    "            while i in idx: # Make sure the translation to do is not in the examples\n",
    "                offset_seed += 1\n",
    "                np.random.seed(i + offset_seed)\n",
    "                idx = np.arange(len(dataset))\n",
    "                idx = np.random.choice(idx, number_examples)\n",
    "            examples = [dataset[f\"{source_lang}-{target_lang}\"][n] for n in idx]\n",
    "            inp = f\"Here are examples of translations from {source_lang_name} to {target_lang_name}:\"\n",
    "            for n in range(number_examples):\n",
    "                example_source, example_target = examples[n][source_lang], examples[n][target_lang]\n",
    "                inp += f\"\\n{source_lang_name}: {example_source} \\n{target_lang_name}: {example_target} \"\n",
    "            inp += f\"\\n Using the examples, translate from {source_lang_name} to {target_lang_name}:\"\n",
    "            input_source = dataset[f\"{source_lang}-{target_lang}\"][i][source_lang]\n",
    "            inp += f\"\\n{source_lang_name}: {input_source} \\n{target_lang_name}:\"\n",
    "            inputs.append(inp)\n",
    "\n",
    "        targets = [example[target_lang] for example in dataset[f\"{source_lang}-{target_lang}\"]]\n",
    "        return sources, inputs, targets\n",
    "    return get_input_targets_icl_ALMA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altegrad-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
